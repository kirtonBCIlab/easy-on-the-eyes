{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG SNR Batch\n",
    "This notebook takes multiple `.npy` and `.json` files and computes the modified SNR for all the epochs in the `npy` file.\n",
    "\n",
    "## Import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom libraries\n",
    "from Functions import processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:45: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<string>:48: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:48: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<string>:45: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<string>:48: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:45: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:48: SyntaxWarning: invalid escape sequence '\\{'\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21876\\4276990569.py:45: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  eeg_epochs[f] = np.load(f\"Data\\{file}.npy\")\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21876\\4276990569.py:48: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  with open(f\"Data\\{file}.json\", \"r\") as file_object:\n"
     ]
    }
   ],
   "source": [
    "# List of file names to be processed\n",
    "files = [       \n",
    "    \"sub-P003_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P003_ses-S002_task-T1_run-001_eeg\",\n",
    "    \"sub-P004_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P004_ses-S002_task-T1_run-001_eeg\",\n",
    "    \"sub-P004_ses-S002_task-T1_run-002_eeg\",\n",
    "    \"sub-P005_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P005_ses-S001_task-T1_run-002_eeg\",\n",
    "    \"sub-P005_ses-S001_task-T1_run-003_eeg\",\n",
    "    \"sub-P005_ses-S002_task-T1_run-001_eeg\",\n",
    "    \"sub-P006_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P006_ses-S002_task-T1_run-001_eeg\",\n",
    "    \"sub-P006_ses-S002_task-T1_run-002_eeg\",\n",
    "    \"sub-P007_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P007_ses-S001_task-T1_run-002_eeg\",\n",
    "    \"sub-P007_ses-S002_task-T1_run-001_eeg\",\n",
    "    \"sub-P008_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P008_ses-S002_task-T1_run-001_eeg\",\n",
    "    \"sub-P008_ses-S002_task-T1_run-002_eeg\",\n",
    "    \"sub-P009_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P009_ses-S002_task-T1_run-001_eeg\",\n",
    "    \"sub-P010_ses-S001_task-T1_run-001_eeg\",\n",
    "    \"sub-P010_ses-S002_task-T1_run-001_eeg\"\n",
    "]\n",
    "\n",
    "# Enable to run files in Daniel's PC\n",
    "# files = [\n",
    "#     \"sub-P004_ses-S001_task-T1_run-001_eeg\",\n",
    "#     \"sub-P004_ses-S002_task-T1_run-002_eeg\",\n",
    "#     ]\n",
    "\n",
    "#isolate subject IDs\n",
    "subject_ids = [file.split('_')[0] for file in files]\n",
    "unique_subject_ids = list(set(subject_ids))\n",
    "\n",
    "# Preallocate variables\n",
    "eeg_epochs = [None] * len(files)\n",
    "settings = [None] * len(files)\n",
    "\n",
    "\n",
    "# Import data\n",
    "for f, file in enumerate(files):\n",
    "    # Import EEG data\n",
    "    eeg_epochs[f] = np.load(f\"Data\\{file}.npy\")\n",
    "\n",
    "    # Import settings\n",
    "    with open(f\"Data\\{file}.json\", \"r\") as file_object:\n",
    "        settings[f] = json.load(file_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Power Spectral Density (PSD)\n",
    "\n",
    "Compute the PSD of all the epoch for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSD settings\n",
    "window_size = 4 # Length of window for PSD [sec]\n",
    "\n",
    "# Preallocate variables\n",
    "eeg_f = [None] * len(files)\n",
    "eeg_pxx = [None] * len(files)   # Preallocate to list in case not all files have the same number of channels\n",
    "\n",
    "# Compute PSD for each file\n",
    "for f,_ in enumerate(files):\n",
    "    [eeg_f[f], eeg_pxx[f]] = signal.welch(\n",
    "        x = eeg_epochs[f],\n",
    "        fs = settings[f][\"eeg_srate\"],\n",
    "        nperseg = window_size*settings[f][\"eeg_srate\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize PSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "plot_psd = False    # Enable to see plots\n",
    "f_limits = [5, 40]  # Frequency limits for the plots [min, max][Hz]\n",
    "file_to_plot = 0    # Select index of file to be plotted \n",
    "\n",
    "if plot_psd:\n",
    "    for s, stim in settings[file_to_plot][\"stimuli\"].items():\n",
    "        fig, ax = plt.subplots(2,2)\n",
    "        fig.suptitle(stim)\n",
    "\n",
    "        for f, freq in settings[file_to_plot][\"freqs\"].items():\n",
    "            fmask = (eeg_f[file_to_plot]>=f_limits[0]) & (eeg_f[file_to_plot]<=f_limits[1])\n",
    "            temp_freq = eeg_f[file_to_plot][fmask]\n",
    "\n",
    "            temp_mean = np.mean(eeg_pxx[file_to_plot][int(s), int(f), :, :], axis=0)[fmask]\n",
    "            temp_sd = np.std(eeg_pxx[file_to_plot][int(s), int(f), :, :], axis=0)[fmask]\n",
    "\n",
    "            row = int(f) // 2\n",
    "            col = int(f) % 2\n",
    "            ax[row, col].plot(temp_freq, temp_mean, '-')\n",
    "            ax[row, col].set_title(f\"{freq} Hz\")\n",
    "            \n",
    "        \n",
    "        ax[0,0].set_ylabel(\"PXX [$\\mu$V$^2$/Hz]\")\n",
    "        ax[1,0].set_ylabel(\"PXX [$\\mu$V$^2$/Hz]\")\n",
    "        ax[1,0].set_xlabel(\"Frequency [Hz]\")\n",
    "        ax[1,1].set_xlabel(\"Frequency [Hz]\")\n",
    "        plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute SNR\n",
    "\n",
    "Compute modified SNR as described in [Norcia et al., 2015.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4581566/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "noise_band = 0.5    # Single sided noise band [Hz]\n",
    "nharms = 2          # Number of harmonics use [n]\n",
    "db_out = True       # Boolean to get output in dB\n",
    "\n",
    "# Preallocate variables\n",
    "snr = [None] * len(files)\n",
    "\n",
    "for f0,_ in enumerate(files):\n",
    "    # Preallocate temp_snr\n",
    "    temp_snr = np.zeros([\n",
    "        len(settings[f0][\"stimuli\"]),\n",
    "        len(settings[f0][\"freqs\"]),\n",
    "        len(settings[f0][\"ch_names\"])\n",
    "        ])\n",
    "\n",
    "    # Compute SNR per stimuli and freq\n",
    "    for s,stimuli in settings[f0][\"stimuli\"].items():\n",
    "        for f1,freq in settings[f0][\"freqs\"].items():\n",
    "                temp_snr[int(s),int(f1),:] = processing.ssvep_snr(\n",
    "                    f = eeg_f[f0],\n",
    "                    pxx = eeg_pxx[f0][int(s),int(f1),:,:],\n",
    "                    stim_freq = float(freq),\n",
    "                    noise_band = noise_band,\n",
    "                    nharms = nharms,\n",
    "                    db_out = db_out\n",
    "                    )\n",
    "                \n",
    "    # Save temp SNR value\n",
    "    snr[f0] = temp_snr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export SNR\n",
    "\n",
    "Create a `pd.DataFrame` to store all the SNR values with appropriate labels and export to CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial sub-P006_ses-S002_task-T1_run-001_eeg has no channel O1 in dataset\n",
      "Trial sub-P006_ses-S002_task-T1_run-002_eeg has no channel O1 in dataset\n",
      "Trial sub-P010_ses-S001_task-T1_run-001_eeg has no channel O2 in dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:51: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:51: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21876\\4058586251.py:51: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  snr_df.to_csv(\"Data\\snr_complete.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "save_snr = True     # Boolean to save SNRs to CSV\n",
    "ch_subset = [\"O1\", \"O2\", \"Oz\"]\n",
    "\n",
    "# Preallocate empty list to store all dataFrames\n",
    "dfs = []\n",
    "\n",
    "for f0,file in enumerate(files):\n",
    "    # Preallocate variables\n",
    "    col_names = []\n",
    "\n",
    "    # There is a more elegant way to do this transposing and reshaping the\n",
    "    # numpy array, but I'll just leave it like this for now.\n",
    "    # Might revisit if execution is too slow\n",
    "    snr_shape = snr[f0].shape\n",
    "    temp_snr = np.zeros((snr_shape[2], snr_shape[0]*snr_shape[1]))\n",
    "    col_idx = 0\n",
    "    for s,stimuli in settings[f0][\"stimuli\"].items():\n",
    "        for f1,freq in settings[f0][\"freqs\"].items():\n",
    "            temp_snr[:,col_idx] = snr[f0][int(s),int(f1),:]\n",
    "            col_names.append(f\"{stimuli} - {freq} Hz\")\n",
    "\n",
    "            col_idx += 1\n",
    "\n",
    "    # Find indices of channel subset\n",
    "    ch_subset_index = []\n",
    "    row_names = []\n",
    "    for channel in ch_subset:\n",
    "        try:\n",
    "            ch_subset_index.append(settings[f0][\"ch_names\"].index(channel))\n",
    "            subject_id = file.split(\"_\")[0]\n",
    "            row_names.append(f\"{subject_id} - {channel}\")\n",
    "        except ValueError:\n",
    "            print(f\"Trial {file} has no channel {channel} in dataset\")\n",
    "            \n",
    "    # Create dataFrame for file\n",
    "    dfs.append(\n",
    "        pd.DataFrame(\n",
    "            data = temp_snr[ch_subset_index, :],\n",
    "            columns = col_names,\n",
    "            index = row_names\n",
    "            )\n",
    "        )\n",
    "    \n",
    "\n",
    "# Concatenate all dataFrames\n",
    "snr_df = pd.concat(dfs)\n",
    "\n",
    "# Save SNRs to CSV\n",
    "if (save_snr):\n",
    "    snr_df.to_csv(\"Data\\snr_complete.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
