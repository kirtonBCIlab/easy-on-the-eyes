{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSVEP classification comparison\n",
    "\n",
    "This notebook takes the SSVEP epochs and the no stim periods and used a classifier.\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "\n",
    "# Custom libraries\n",
    "from Functions import import_data\n",
    "from Functions import data_tools\n",
    "from Functions import processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:20: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<string>:20: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\{'\n",
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_27012\\3025111396.py:20: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  [marker_ts, markers] = import_data.read_xdf_unity_markers(f\"Data\\{file}.xdf\")\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "files = [  \n",
    "    \"sub-P004_ses-S001_task-T1_run-001_eeg\"\n",
    "    # \"sub-P002_ses-S001_task-T1_run-001_eeg\"   \n",
    "]\n",
    "ch_names = [\"O1\", \"Oz\" ,\"O2\"] # List of channel names to import\n",
    "fc = [1, 35]            # Cut-off frequencies for BW filter\n",
    "\n",
    "# Isolate subject IDs\n",
    "subject_ids = [file.split('_')[0] for file in files]\n",
    "unique_subject_ids = list(set(subject_ids))\n",
    "\n",
    "# Preallocate variables\n",
    "eeg_epochs = [None] * len(files)\n",
    "settings = [None] * len(files)\n",
    "\n",
    "for f, file in enumerate(files):\n",
    "    # Import data and markers\n",
    "    [eeg_ts, eeg_data, eeg_fs] = import_data.read_xdf(fr\"Data\\\\{file}.xdf\", picks=ch_names)  \n",
    "    [marker_ts, markers] = import_data.read_xdf_unity_markers(f\"Data\\{file}.xdf\")\n",
    "\n",
    "    # Filter data\n",
    "    eeg_filt = processing.butter_filt(eeg_data, fc, \"bandpass\", eeg_fs)\n",
    "\n",
    "    # Create epochs from Unity markers\n",
    "    (eeg_epochs, epoch_labels) = data_tools.epochs_from_unity_markers(\n",
    "        eeg_time = eeg_ts,\n",
    "        eeg_data = eeg_filt,\n",
    "        marker_time = marker_ts,\n",
    "        marker_data = markers\n",
    "        )\n",
    "\n",
    "    # Fix mispelled labels & create numeric code for them\n",
    "    fixed_labels = data_tools.fix_labels(epoch_labels) \n",
    "\n",
    "    #drop resting state labels and epochs\n",
    "    labels_to_drop = [\"Resting state, eyes open\", \"Resting state, eyes closed\"]\n",
    "    drop_rs_epochs, drop_rs_labels = data_tools.drop_epochs_by_label(eeg_epochs, fixed_labels, labels_to_drop)\n",
    "\n",
    "    [label_dict, label_array] = data_tools.labels_to_dict_and_array(drop_rs_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim epochs so that they can be in numpy array instead of list\n",
    "trimmed_epochs = data_tools.normalize_epochs_length(drop_rs_epochs, \"zeropad\")\n",
    "#time base epoch by 4 seconds \n",
    "#\"off\" = 2 4 second\n",
    "#\"on\" = 3 4 second \n",
    "\n",
    "#either 0 pad the off into 12 seconds or trim epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riemmanian geometry classification imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7355473554735548"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "# Create classifier\n",
    "pipelines_fb = make_pipeline(\n",
    "    Covariances(estimator=\"lwf\"),\n",
    "    TangentSpace(),\n",
    "    LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n",
    "    )\n",
    "\n",
    "# Oversample stimulus classes\n",
    "sm = ADASYN(\n",
    "    random_state = 42, \n",
    "    n_neighbors = 2     #2 id there are 3 samples of \"on\"\n",
    ")\n",
    "[nepochs, nchans, nsamples] = np.shape(trimmed_epochs)\n",
    "reshaped_epochs = np.reshape(trimmed_epochs, [nepochs, nchans*nsamples])\n",
    "[x_oversampled, y_oversampled] = sm.fit_resample(reshaped_epochs, label_array)\n",
    "\n",
    "# - Reshape oversampled data to be [epoch, channel, samples]\n",
    "x_oversampled_unfold = np.reshape(\n",
    "    x_oversampled,\n",
    "    [x_oversampled.shape[0], nchans, -1]\n",
    "    )\n",
    "\n",
    "# Split data\n",
    "[X_train, X_test, y_train, y_test] = train_test_split(x_oversampled_unfold, y_oversampled, random_state= 4)\n",
    "\n",
    "# Test classifier\n",
    "pipelines_fb.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipelines_fb.predict(X_test)\n",
    "cm_all = cm(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single stimulus type classification\n",
    "\n",
    "This section takes a string to select the type of stimulus you want and it does the same Riemmanian classification as above using the `stimulus_of_interest` and the `Stimulus Off` events that precede `stimulus_of_interest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings\n",
    "stimulus_of_interest = \" Voronoi\"   # Note that there is a space before the name\n",
    "\n",
    "# Create mask and labels for stimulus of interest\n",
    "(single_labels, bool_mask) = data_tools.single_stimulus_mask(drop_rs_labels, \" SquareGrate\")\n",
    "single_stimulus_epochs = trimmed_epochs[bool_mask, : , :]\n",
    "\n",
    "# Reshape data to solve imbalance in classes\n",
    "[nepochs, nchans, nsamples] = np.shape(single_stimulus_epochs)\n",
    "reshaped_epochs = np.reshape(single_stimulus_epochs, [nepochs, nchans*nsamples])\n",
    "[x_oversampled, y_oversampled] = sm.fit_resample(reshaped_epochs, single_labels)\n",
    "\n",
    "# Reshape oversampled data to be [epoch, channel, samples]\n",
    "x_oversampled_unfold = np.reshape(\n",
    "    x_oversampled,\n",
    "    [x_oversampled.shape[0], nchans, -1]\n",
    "    )\n",
    "\n",
    "# Split data\n",
    "[X_train_single, X_test_single, y_train_single, y_test_single] = train_test_split(\n",
    "    x_oversampled_unfold,\n",
    "    y_oversampled,\n",
    "    random_state= 4)\n",
    "\n",
    "# Test classifier\n",
    "pipelines_fb.fit(X_train_single, y_train_single).score(X_test_single, y_test_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_single = pipelines_fb.predict(X_test_single)\n",
    "cm_single = cm(y_test_single, y_pred_single)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne-2023.yml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
